# mlops-irisapi-docker-k8s-cd
Sure, Satyam! Here's a clean, professional `README.md` file for your **Iris Classification API with CI/CD on GKE** setup:

---

## ğŸ§  Iris Classification API (CI/CD with GCP GKE & GitHub Actions)

This project serves a **Machine Learning API** that classifies Iris flower species using a trained `model.pkl`. It is containerized using Docker and deployed to **Google Kubernetes Engine (GKE)** with a complete **CI/CD pipeline using GitHub Actions**.

---

## ğŸ“¦ Project Structure

```bash
.
â”œâ”€â”€ Dockerfile                # Defines API container image
â”œâ”€â”€ model/
â”‚   â””â”€â”€ model.pkl             # Trained scikit-learn model
â”œâ”€â”€ app.py                   # Flask-based API
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ kubernetes/
â”‚   â”œâ”€â”€ deployment.yaml      # Kubernetes deployment config
â”‚   â””â”€â”€ service.yaml         # Kubernetes LoadBalancer service
â””â”€â”€ .github/
    â””â”€â”€ workflows/
        â””â”€â”€ cd.yaml          # GitHub Actions CD workflow
```

---

## ğŸš€ How It Works

### ğŸ›  API Functionality

POST `/predict/`

```json
{
  "sepal_length": 5.1,
  "sepal_width": 3.5,
  "petal_length": 1.4,
  "petal_width": 0.2
}
```

Response:

```json
{
  "predicted_class": "setosa"
}
```

### ğŸ“¦ Containerization

Docker is used to package the Flask app and model into a deployable container:

```bash
docker build -t gcr.io/<project-id>/iris-api:latest .
docker push gcr.io/<project-id>/iris-api:latest
```

---

## ğŸ” Continuous Deployment

### âœ… Trigger:

Every push to the `main` branch triggers:

1. Docker build & push to Google Container Registry (GCR)
2. GKE deployment update using `kubectl set image`

### âœ… Secrets Needed (GitHub > Settings > Secrets and variables > Actions):

| Secret Key         | Purpose                              |
| ------------------ | ------------------------------------ |
| `GCP_SA_KEY`       | JSON credentials for service account |
| `GCP_PROJECT_ID`   | GCP Project ID                       |
| `GCP_CLUSTER_NAME` | Name of your GKE cluster             |
| `GCP_REGION`       | Region of your GKE cluster           |

---

## â˜ï¸ Kubernetes Deployment

You must first apply the manifests:

```bash
kubectl apply -f kubernetes/deployment.yaml
kubectl apply -f kubernetes/service.yaml
```

> This creates a deployment and exposes the app through a GCP LoadBalancer.

---

## ğŸŒ Test the Endpoint

```bash
curl -X POST http://<EXTERNAL-IP>/predict/ \
  -H "Content-Type: application/json" \
  -d '{"sepal_length": 6.1, "sepal_width": 2.8, "petal_length": 4.7, "petal_width": 1.2}'
```

---

## âœ… Prerequisites

* Google Cloud Project with GKE and GCR enabled
* Docker installed locally (for manual testing)
* `kubectl` & `gcloud` installed and authenticated
* GitHub repository connected with proper secrets

---

## ğŸ§ª TODO / Extensions

* âœ… Add CI step (unit test / pytest / CML)
* â³ Add monitoring (Prometheus/Grafana)
* â³ Use Helm charts for better config management
* â³ Add MLflow/Feast integration (if part of full pipeline)

---

## ğŸ‘¨â€ğŸ’» Author

**Satyam Srivastava**
Iris Deployment Project | GCP + GKE + CI/CD | MLOps Week 6

---

Let me know if you want the README in **PDF format** too.
